{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import IntegerType, StringType, TimestampType\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window as W\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "\n",
    "First, we define the data schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('rental_id', IntegerType(), True),\n",
    "    StructField('duration', IntegerType(), True),\n",
    "    StructField('bike_id', IntegerType(), True),\n",
    "    StructField('end_date', TimestampType(), True),\n",
    "    StructField('end_station_id', IntegerType(), True),\n",
    "    StructField('end_station_name', StringType(), True),\n",
    "    StructField('start_date', TimestampType(), True),\n",
    "    StructField('start_station_id', IntegerType(), True),\n",
    "    StructField('start_station_name', StringType(), True),\n",
    "    StructField('end_station_logical_terminal', IntegerType(), True),\n",
    "    StructField('start_station_logical_terminal', IntegerType(), True),\n",
    "    StructField('end_station_priority_id', IntegerType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rental_id: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- bike_id: integer (nullable = true)\n",
      " |-- end_date: timestamp (nullable = true)\n",
      " |-- end_station_id: integer (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- start_date: timestamp (nullable = true)\n",
      " |-- start_station_id: integer (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- end_station_logical_terminal: integer (nullable = true)\n",
      " |-- start_station_logical_terminal: integer (nullable = true)\n",
      " |-- end_station_priority_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read \\\n",
    "    .options(header='true', enforceSchema='false', timestampFormat=\"yyyy-MM-dd HH:mm:ss zzz\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('/input/assignments/london_bicycles/london_bicycles_hire.csv')\n",
    "\n",
    "data.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering data\n",
    "\n",
    "Now, we will filter out data not compliant with the task's requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_duration = 10 * 60  # duration has to be at least 10 minutes\n",
    "not_nullable_columns = ['duration', 'start_station_id',\n",
    "                        'start_station_name', 'end_station_id', 'end_station_name']\n",
    "\n",
    "filtered_data = data \\\n",
    "    .where((F.year(data.start_date) == 2016) & (F.year(data.end_date) == 2016)) \\\n",
    "    .na.drop(subset=not_nullable_columns) \\\n",
    "    .where(data.duration >= min_duration) \\\n",
    "    .where(F.dayofyear(data.start_date) == F.dayofyear(data.end_date)) \\\n",
    "    .where(data.start_station_id != data.end_station_id)\n",
    "\n",
    "# now we can drop unnecessary columns and store the month and the day of the week instead of timestamps\n",
    "# since this is all we actually need\n",
    "filtered_data = filtered_data.select(\n",
    "    F.month(filtered_data.start_date).alias('month'),\n",
    "    F.date_format(filtered_data.start_date, \"u\").cast('int').alias('day_of_week'),\n",
    "    filtered_data.duration,\n",
    "    filtered_data.start_station_id,\n",
    "    filtered_data.start_station_name,\n",
    "    filtered_data.end_station_id,\n",
    "    filtered_data.end_station_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to organize ordered start/end stations into unordered routes.\n",
    "\n",
    "To do this, we will store the stations as columns A and B.\n",
    "Column A will contain the station that has a smaller id while column B will store the other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_data = filtered_data.select(\n",
    "    filtered_data.month, filtered_data.day_of_week, filtered_data.duration,\n",
    "    F.least(filtered_data.start_station_id, filtered_data.end_station_id).alias('station_A_id'),\n",
    "    F.greatest(filtered_data.start_station_id, filtered_data.end_station_id).alias('station_B_id')\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also cache data about station names and their ids, so we can join later with the final result to get station ids to names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_stations = filtered_data.select(\n",
    "    filtered_data.start_station_id.alias('id'),\n",
    "    filtered_data.start_station_name.alias('name')\n",
    ")\n",
    "end_stations = filtered_data.select(\n",
    "    filtered_data.end_station_id.alias('id'),\n",
    "    filtered_data.end_station_name.alias('name')\n",
    ")\n",
    "\n",
    "station_data = start_stations.union(end_stations).distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can filter out routes with less than a 100 records in a given month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_route_window = W.partitionBy(\n",
    "    route_data.month, route_data.station_A_id, route_data.station_B_id)\n",
    "\n",
    "counted_monthly_route_data = route_data.select(\n",
    "    '*', F.count('*').over(monthly_route_window).alias('trips_this_month'))\n",
    "\n",
    "filtered_data = counted_monthly_route_data.where(counted_monthly_route_data.trips_this_month >= 100)\n",
    "filtered_data = filtered_data.drop('trips_this_month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so we have successfully filtered the data. Now, we can cache the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_data = filtered_data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial filtered data for querying looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route_data schema:\n",
      "root\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- station_A_id: integer (nullable = true)\n",
      " |-- station_B_id: integer (nullable = true)\n",
      "\n",
      "station_data schema:\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('route_data schema:')\n",
    "route_data.printSchema()\n",
    "print('station_data schema:')\n",
    "station_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate average durations for weekdays and for weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekdays averages count: 1556\n",
      "Weekend averages count: 1406\n"
     ]
    }
   ],
   "source": [
    "weekdays_monthly_avgs = route_data.where(route_data.day_of_week < 6) \\\n",
    "    .groupBy(route_data.month, route_data.station_A_id, route_data.station_B_id) \\\n",
    "    .agg(F.avg('duration').alias('weekday_avg'))\n",
    "\n",
    "weekend_monthly_avgs = route_data.where(route_data.day_of_week >= 6) \\\n",
    "    .groupBy(route_data.month, route_data.station_A_id, route_data.station_B_id) \\\n",
    "    .agg(F.avg('duration').alias('weekend_avg'))\n",
    "\n",
    "print(f\"Weekdays averages count: {weekdays_monthly_avgs.count()}\")\n",
    "print(f\"Weekend averages count: {weekend_monthly_avgs.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that not every route has a calculated average for both weekdays and weekends \n",
    "\n",
    "*(perhaps data from this days is missing or some stations are closed on weekends, for example)*,\n",
    "\n",
    "so we're going to drop the routes without both averages. This will be done while doing an inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_avgs = weekdays_monthly_avgs.join(weekend_monthly_avgs, ['month', 'station_A_id', 'station_B_id'], 'inner')\n",
    "monthly_avgs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the **weekday_avg/weekend_avg ratios** and order them by ratio desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ratios = monthly_avgs.select(\n",
    "    monthly_avgs.month,\n",
    "    monthly_avgs.station_A_id,\n",
    "    monthly_avgs.station_B_id,\n",
    "    (monthly_avgs.weekday_avg / monthly_avgs.weekend_avg).alias('ratio')\n",
    ").withColumn(\n",
    "    'rank', F.rank().over(W.partitionBy('month').orderBy(F.desc('ratio')))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used rank instead of dense_rank, now we can just take rows with **rank <= 2**. This way we'll take all rows with rank 1 and, if there is only 1 row with rank 1 for a given month, take rows with rank 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_monthly = monthly_ratios.where(monthly_ratios.rank <= 2).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so, one final thing to do is to change station ids into station names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_monthly_with_names = top_monthly \\\n",
    "    .join(station_data, top_monthly.station_A_id == station_data.id) \\\n",
    "    .select(top_monthly['*'], station_data.name.alias('station_A_name'))\n",
    "\n",
    "top_monthly_with_names = top_monthly_with_names \\\n",
    "    .join(station_data, top_monthly_with_names.station_B_id == station_data.id) \\\n",
    "    .select(top_monthly_with_names['*'], station_data.name.alias('station_B_name'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so, one final thing is to format the final result, so it contains only necessary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final result:\n",
      "+-----+----------------------------------------------+-------------------------------------------------+------------------+\n",
      "|month|station_A_name                                |station_B_name                                   |ratio             |\n",
      "+-----+----------------------------------------------+-------------------------------------------------+------------------+\n",
      "|1    |Aquatic Centre, Queen Elizabeth Olympic Park  |Lee Valley VeloPark, Queen Elizabeth Olympic Park|1.268274812602153 |\n",
      "|1    |Eccleston Place, Victoria                     |Eastbourne Mews, Paddington                      |1.1965811965811965|\n",
      "|2    |Albert Gate, Hyde Park                        |Queen's Gate, Kensington Gardens                 |1.7529734183563805|\n",
      "|2    |Finsbury Circus, Liverpool Street             |Waterloo Station 1, Waterloo                     |1.5393258426966292|\n",
      "|3    |Crosswall, Tower                              |Waterloo Station 1, Waterloo                     |1.5388026607538803|\n",
      "|3    |Hyde Park Corner, Hyde Park                   |Speakers' Corner 1, Hyde Park                    |1.341545052885259 |\n",
      "|4    |Belgrove Street , King's Cross                |Northumberland Avenue, Strand                    |1.2959435626102294|\n",
      "|4    |Serpentine Car Park, Hyde Park                |Black Lion Gate, Kensington Gardens              |1.2957027540360875|\n",
      "|5    |Hyde Park Corner, Hyde Park                   |Storey's Gate, Westminster                       |2.14872901119403  |\n",
      "|5    |East Village, Queen Elizabeth Olympic Park    |Aquatic Centre, Queen Elizabeth Olympic Park     |1.549878640776699 |\n",
      "|6    |Park Road (Baker Street), The Regent's Park   |London Zoo,  The Regent's Park                   |1.7102302130616713|\n",
      "|6    |Triangle Car Park, Hyde Park                  |Green Park Station, Mayfair                      |1.4917159763313608|\n",
      "|7    |Green Street, Mayfair                         |Triangle Car Park, Hyde Park                     |1.8268727684095165|\n",
      "|7    |East Village, Queen Elizabeth Olympic Park    |Podium, Queen Elizabeth Olympic Park             |1.6175931748270764|\n",
      "|8    |Queen's Circus, Battersea Park                |Sopwith Way, Battersea Park                      |1.6915306655986828|\n",
      "|8    |Wellington Arch, Hyde Park                    |Palace Gate, Kensington Gardens                  |1.5003335557038027|\n",
      "|9    |Wellington Arch, Hyde Park                    |Queen's Gate, Kensington Gardens                 |1.7867634500426985|\n",
      "|9    |Copper Box Arena, Queen Elizabeth Olympic Park|Podium, Queen Elizabeth Olympic Park             |1.7309442761131684|\n",
      "|10   |Triangle Car Park, Hyde Park                  |Queen's Gate, Kensington Gardens                 |1.5473633558400293|\n",
      "|10   |Finsbury Circus, Liverpool Street             |Waterloo Station 3, Waterloo                     |1.4538695505238257|\n",
      "|11   |Black Lion Gate, Kensington Gardens           |Queen's Gate, Kensington Gardens                 |1.5203061782394751|\n",
      "|11   |Belgrove Street , King's Cross                |Museum of London, Barbican                       |1.3537190082644628|\n",
      "|12   |Finsbury Circus, Liverpool Street             |Waterloo Station 3, Waterloo                     |1.2488947833775421|\n",
      "|12   |Holborn Circus, Holborn                       |Waterloo Station 1, Waterloo                     |1.248             |\n",
      "+-----+----------------------------------------------+-------------------------------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_result = top_monthly_with_names \\\n",
    "    .orderBy(top_monthly_with_names.month.asc(), top_monthly_with_names.rank.asc()) \\\n",
    "    .select('month', 'station_A_name', 'station_B_name', 'ratio')\n",
    "\n",
    "print(\"The final result:\")\n",
    "final_result.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[IPyKernel] PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
